---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ceph-bridge
  namespace: openstack
  # REMOVE hook annotation; keep only wave to ensure it lands early
  annotations:
    argocd.argoproj.io/sync-wave: "-4"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ceph-bridge-rook-reader
  namespace: rook-ceph
  annotations:
    argocd.argoproj.io/sync-wave: "-4"
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["rook-ceph-config","rook-ceph-admin-keyring","rook-ceph-mon"]
    verbs: ["get"]
  # (Optional) uncomment if you ever read this configmap
  # - apiGroups: [""]
  #   resources: ["configmaps"]
  #   resourceNames: ["rook-ceph-mon-endpoints"]
  #   verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ceph-bridge-openstack-writer
  namespace: openstack
  annotations:
    argocd.argoproj.io/sync-wave: "-4"
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["ceph-etc"]
    verbs: ["get","update","patch"]
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["pvc-ceph-client-key"]
    verbs: ["get","update","patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ceph-bridge-rook-reader-binding
  namespace: rook-ceph
  annotations:
    argocd.argoproj.io/sync-wave: "-3"
subjects:
  - kind: ServiceAccount
    name: ceph-bridge
    namespace: openstack
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ceph-bridge-rook-reader
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ceph-bridge-openstack-writer-binding
  namespace: openstack
  annotations:
    argocd.argoproj.io/sync-wave: "-3"
subjects:
  - kind: ServiceAccount
    name: ceph-bridge
    namespace: openstack
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ceph-bridge-openstack-writer
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ceph-bridge-osh-writer
  namespace: osh-infra
  annotations:
    argocd.argoproj.io/sync-wave: "-4"
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["create"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["ceph-etc"]
    verbs: ["get","update","patch"]
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["pvc-ceph-client-key"]
    verbs: ["get","update","patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ceph-bridge-osh-writer-binding
  namespace: osh-infra
  annotations:
    argocd.argoproj.io/sync-wave: "-3"
subjects:
  - kind: ServiceAccount
    name: ceph-bridge
    namespace: openstack
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ceph-bridge-osh-writer
---
apiVersion: batch/v1
kind: Job
metadata:
  name: ceph-bridge-presync
  namespace: openstack
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
    argocd.argoproj.io/sync-wave: "-2"   # runs AFTER all RBAC (waves -4/-3)
spec:
  backoffLimit: 3
  template:
    spec:
      serviceAccountName: ceph-bridge
      # (defensive) make sure a token is mounted even if your cluster default changed
      automountServiceAccountToken: true
      restartPolicy: Never
      containers:
        - name: kubectl
          image: docker.io/bitnami/kubectl:latest
          imagePullPolicy: IfNotPresent
          env:
            - name: TARGET_NAMESPACES
              value: "openstack osh-infra"
          command: ["/bin/sh","-c"]
          args:
            - |
              set -euo pipefail
              echo "[0/3] Target namespaces: ${TARGET_NAMESPACES}"

              echo "[1/3] Building ceph.conf from rook-ceph-config"
              MH_B64=$(kubectl -n rook-ceph get secret rook-ceph-config -o jsonpath='{.data.mon_host}' || true)
              MIM_B64=$(kubectl -n rook-ceph get secret rook-ceph-config -o jsonpath='{.data.mon_initial_members}' || true)
              if [ -z "${MH_B64}" ] || [ -z "${MIM_B64}" ]; then
                echo "ERROR: rook-ceph-config is missing mon_host/mon_initial_members"; exit 1
              fi
              MON_HOST=$(printf "%s" "${MH_B64}" | base64 -d | tr -d '\r')
              MON_MEMBERS=$(printf "%s" "${MIM_B64}" | base64 -d | tr -d ' \r\n')
              FSID_B64=$(kubectl -n rook-ceph get secret rook-ceph-mon -o jsonpath='{.data.fsid}' 2>/dev/null || true)
              FSID=""
              [ -n "${FSID_B64}" ] && FSID=$(printf "%s" "${FSID_B64}" | base64 -d | tr -d '\r')

              cat >/work/ceph.conf <<EOF
              [global]
              mon_host = ${MON_HOST}
              mon_initial_members = ${MON_MEMBERS}
              EOF
              if [ -n "${FSID}" ]; then echo "fsid = ${FSID}" >> /work/ceph.conf; fi

              echo "[2/3] Upsert ceph-etc ConfigMap and pvc-ceph-client-key Secret to targets"
              KEY_B64=$(kubectl -n rook-ceph get secret rook-ceph-admin-keyring -o jsonpath='{.data.keyring}')
              KEY_RAW=$(printf "%s" "$KEY_B64" | base64 -d | sed -n 's/^[[:space:]]*key[[:space:]]*=[[:space:]]*\(.*\)$/\1/p' | tr -d '\r')
              if [ -z "${KEY_RAW}" ]; then
                echo "ERROR: failed to parse admin key from rook-ceph-admin-keyring"; exit 1
              fi

              for NS in ${TARGET_NAMESPACES}; do
                echo "  - Namespace ${NS}: applying ceph-etc"
                kubectl -n "${NS}" create configmap ceph-etc \
                  --from-file=ceph.conf=/work/ceph.conf \
                  --dry-run=client -o yaml | kubectl apply -f -

                echo "  - Namespace ${NS}: applying pvc-ceph-client-key"
                kubectl -n "${NS}" create secret generic pvc-ceph-client-key \
                  --from-literal=key="${KEY_RAW}" \
                  --dry-run=client -o yaml | kubectl apply -f -
              done

              echo "[3/3] Done."
          volumeMounts:
            - name: work
              mountPath: /work
      volumes:
        - name: work
          emptyDir: {}
